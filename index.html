

<!doctype html>
<html>

<head>


<title>Shun Lu</title>

<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="keywords" content="Shun Lu, 陆顺, Institute of Computing Technology (ICT), Chinese Academy of Sciences">
<meta name="description" content="Shun Lu's home page">
<link rel="stylesheet" href="css/jemdoc.css" type="text/css" />

<script>
   function showPubs(id) {
  if (id == 0) {
    document.getElementById('pubs').innerHTML = document.getElementById('pubs_selected').innerHTML;
    document.getElementById('select0').style = 'text-decoration:underline;color:#000000';
    document.getElementById('select1').style = '';
  } else {
    document.getElementById('pubs').innerHTML = document.getElementById('pubs_by_topic').innerHTML;
    document.getElementById('select1').style = 'text-decoration:underline;color:#000000';
    document.getElementById('select0').style = '';
  }
}

</script>

</head>


<body>

<div id="layout-content" style="margin-top:25px">


<table>
	<tbody>
		<tr>
			<td width="75%">
				<div id="toptitle">
					<h1>Shun Lu 陆顺<h1>
				</div>

		<p>
			PHD Candidate </br>
			Email: lushun901@gmail.com </br>
		</p>
		<p>
			<a href="https://github.com/ShunLu91"><img src="assets/logos/github_logo.png" height="30px"></a>&nbsp;&nbsp;
			<a href="https://scholar.google.com/citations?user=-zX83WMAAAAJ&hl=zh-CN"><img src="assets/logos/google_logo.png" height="30px"></a>&nbsp;&nbsp;
			<a href="https://www.zhihu.com/people/lu-shun-40-22"><img src="assets/logos/zhihu_logo.png" height="30px"></a>&nbsp;&nbsp;
		</p>
			</td>

			</td>
			<td width="25%">
				<img src="assets/images/shunlu.png" width="80%"/>
			</td>
		<tr>
	</tbody>
</table>

<h2>News</h2>
<ul>
<li>2023.03.31: We are excited to announce that our lightweight software, <a href= https://github.com/ICT-ANS/StarLight><span style="color: blue; ">StarLight</a>, has been released !
<li>2023.02.28: Our paper PA&DA is accepted by CVPR 2023 ! </li>
<li>2022.11.19: Our paper PINAT is accepted by AAAI 2023 ! </li>
<li>2022.06.15: Our paper ConformerNAS and WA-Transformer are accepted by Interspeech 2022 ! </li>
<li>2021.10.16: Our paper DU-DARTS is accepted by BMVC 2021 ! </li>
<li>2021.09.29: Our paper TANSP is accepted by NeurIPS 2021 ! </li>
<li>2021.05.26: Our team ranked 2nd among all teams in
<a href="https://cvpr21-nas.com/">
<span style="color: blue; ">CVPR 2021 NAS Track 2: Performance Prediction Track</span>
</a>
!
</li>
<li>2021.05.26: Our team ranked 2nd among all teams in
<a href="https://cvpr21-nas.com/">
<span style="color: blue; ">CVPR 2021 NAS Track 1: Supernet Track</span>
</a>
!
</li>

</ul>

<h2>Biography</h2> 
<p>
Shun Lu holds a Bachelor's degree from Beijing University of Science and Technology (USTB) and I am currently a PhD student at the Institute of Computing Technology (ICT), advised by <a href="https://meridiancas.github.io/"><span style="color: blue; ">Yu Hu</a>. My research focuses on the field of computer science, with a particular emphasis on developing algorithms to search for efficient models and compress models. I am passionate about exploring new approaches to these problems and have been fortunate enough to work on several exciting projects during my time at ICT. I am excited to continue my research in this field and to contribute to the advancement of computer science and technology.
</p>
<p>
My research interests include neural architecture search, model compression, audio separation, speaker verification, and semantic segmentation. Regarding neural architecture search, I am working on developing automated methods to design and optimize neural network architectures. This involves exploring different network topologies and architectures to find the optimal solution for a given task. I believe that this research will have significant impact on the development of artificial intelligence and machine learning, and I am excited to be a part of this exciting field.
</p>
<p>
</p>

<h2>Projects</h2>

<table class="imgtable"><tr><td>
<img src="assets/images/thesis/StarLight.png" alt="alt text" width="200" height="130" style="display: block;
margin-left: 20px; margin-right: 20px margin-top: 15px; margin-bottom: 15px;" />
<td align="left" style="padding-left: 50px;">
<p>
	StarLight: An Open-Source AutoML Toolkit for Lightweighting Deep Neural Networks<br />
	<b>Shun Lu</b>, Longxing Yang, Zihao Sun, Jilin Mei, Yu Hu*<br />
	<a href="https://github.com/ICT-ANS/StarLight">[Code]</a><a href="https://github.com/ICT-ANS/StarLight#demo">[Demo]</a><a href="https://ict-ans.github.io/StarLight.github.io/">[Tutorial]</a>
</p>
</td></tr></table>


<h2>Selected Publications</h2>

<table class="imgtable"><tr><td>
<img src="assets/images/thesis/PA-DA.png" alt="alt text" width="240" height="90" style="display: block; margin-top: 35px; margin-bottom: 35px;" />
<td align="left" style="padding-left: 30px;">
<p>
	PA&DA: Jointly Sampling Path and Data for Consistent NAS<br />
	<b>Shun Lu</b>, Yu Hu*, Longxing Yang, Zihao Sun, Jilin Mei, Jianchao Tan, Chengru Song<br />
	[CVPR 2023]<a href="https://openaccess.thecvf.com/content/CVPR2023/html/Lu_PADA_Jointly_Sampling_Path_and_Data_for_Consistent_NAS_CVPR_2023_paper.html">[Paper]</a><a href="https://github.com/ShunLu91/PA-DA">[Code]</a>
</p>
</td></tr></table>

<table class="imgtable"><tr><td>
<img src="assets/images/thesis/PINAT.png" alt="alt text" width="240" height="107" style="display: block; margin-top: 26.5px; margin-bottom: 26.5px;" />
<td align="left" style="padding-left: 30px;">
<p>
	PINAT: A Permutation INvariance Augmented Transformer for NAS Predictor<br />
	<b>Shun Lu</b>, Yu Hu*, Peihao Wang, Yan Han, Jianchao Tan, Jixiang Li, Sen Yang, Ji Liu<br />
	[AAAI 2023][Paper]<a href="https://github.com/ShunLu91/PINAT">[Code]</a>
</p>
</td></tr></table>

<table class="imgtable"><tr><td>
<img src="assets/images/thesis/ConformerNAS.png" alt="alt text" width="207.5" height="160" style="display: block; margin-left: 16.25px; margin-right: 16.25px;" />
<td align="left" style="padding-left: 30px;">
<p>
	Conformer Space Neural Architecture Search for Multi-Task Audio Separation<br />
	<b>Shun Lu</b><sup>&dagger;</sup>, Yang Wang<sup>&dagger;</sup>, Peng Yao<sup>&dagger;</sup>, Chenxing Li, Jianchao Tan, Feng Deng, Xiaorui Wang, Chengru Song<br />
	[Interspeech 2022]<a href="https://www.isca-speech.org/archive/pdfs/interspeech_2022/lu22b_interspeech.pdf">[Paper]</a>
</p>
</td></tr></table>

<table class="imgtable"><tr><td>
<img src="assets/images/thesis/DU_DARTS.png" alt="alt text" width="240" height="106" style="display: block; margin-top: 25px; margin-bottom: 25px;" />
<td align="left" style="padding-left: 30px;">
<p>
	DU-DARTS: Decreasing the Uncertainty of Differentiable NAS<br />
	<b>Shun Lu</b>, Yu Hu*, Longxing Yang, Zihao Sun, Jilin Mei, Yiming Zeng, Xiaowei Li<br />
	[BMVC 2021]<a href="https://www.bmvc2021-virtualconference.com/assets/papers/0209.pdf">[Paper]</a><a href="https://github.com/ShunLu91/DU-DARTS">[Code]</a>
</p>
</td></tr></table>

<table class="imgtable"><tr><td>
<img src="assets/images/thesis/TNASP.png" alt="alt text" width="240" height="140" style="display: block; margin-top: 10px; margin-bottom: 10px;" />
<td align="left" style="padding-left: 30px;">
<p>
	TNASP: A Transformer-based NAS Predictor with a Self-evolution Framework<br />
	<b>Shun Lu</b>, Jixiang Li, Jianchao Tan, Sen Yang, Ji Liu<br />
	[NeurIPS 2021]<a href="https://papers.nips.cc/paper/2021/hash/7fa1575cbd7027c9a799983a485c3c2f-Abstract.html">[Paper]</a>
</p>
</td></tr></table>

<table class="imgtable"><tr><td>
<img src="assets/images/thesis/BurgerFormer.png" alt="alt text" width="240" height="151" style="display: block; margin-top: 4.5px; margin-bottom: 4.5px;" />
<td align="left" style="padding-left: 30px;">
<p>
	Searching for BurgerFormer with Micro-Meso-Macro Space Design<br />
	Longxing Yang, Yu Hu*, <b>Shun Lu</b>, Zihao Sun, Jilin Mei, Yinhe Han, Xiaowei Li<br />
	[ICML 2022]<a href="https://proceedings.mlr.press/v162/yang22f.html">[Paper]</a><a href="https://github.com/xingxing-123/BurgerFormer">[Code]</a>
</p>
</td></tr></table>

<table class="imgtable"><tr><td>
<img src="assets/images/thesis/AGNAS.png" alt="alt text" width="240" height="109" style="display: block; margin-top: 25.5px; margin-bottom: 25.5px;" />
<td align="left" style="padding-left: 30px;">
<p>
	AGNAS: Attention-Guided Micro and Macro-Architecture Search<br />
	Zihao Sun, Yu Hu*, <b>Shun Lu</b>, Longxing Yang, Jilin Mei, Yinhe Han, Xiaowei Li<br />
	[ICML 2022]<a href="https://proceedings.mlr.press/v162/sun22a.html">[Paper]</a><a href="https://github.com/Sunzh1996/AGNAS">[Code]</a>
</p>
</td></tr></table>

<table class="imgtable"><tr><td>
<img src="assets/images/thesis/DDSAS.png" alt="alt text" width="240" height="86.2" style="display: block; margin-top: 36.9px; margin-bottom: 36.9px;" />
<td align="left" style="padding-left: 30px;">
<p>
	DDSAS: Dynamic and Differentiable Space-Architecture Search<br />
	Longxing Yang, Yu Hu*, <b>Shun Lu</b>, Zihao Sun, Jilin Mei, Yiming Zeng, Zhiping Shi, Yinhe Han, Xiaowei Li<br />
	[ACML 2021]<a href="http://www.acml-conf.org/2021/conference/accepted-papers/185/">[Paper]</a><a href="https://github.com/xingxing-123/DDSAS">[Code]</a>
</p>
</td></tr></table>

<table class="imgtable"><tr><td>
<img src="assets/images/thesis/SpeechNAS.png" alt="alt text" width="240" height="116.8" style="display: block; margin-top: 21.6px; margin-bottom: 21.6px;" />
<td align="left" style="padding-left: 30px;">
<p>
	SpeechNAS: Towards Better Trade-off between Latency and Accuracy for Large-Scale Speaker Verification<br />
	Wentao Zhu<sup>&dagger;</sup>, Tianlong Kong<sup>&dagger;</sup>, <b>Shun Lu</b>, Jixiang Li, Dawei Zhang, Feng Deng, Xiaorui Wang, Sen Yang, Ji Liu<br />
	[ASRU 2021]<a href="https://arxiv.org/abs/2109.08839">[Paper]</a><a href="https://github.com/wentaozhu/speechnas">[Code]</a>
</p>
</td></tr></table>

<table class="imgtable"><tr><td>
<img src="assets/images/thesis/DARTS-.png" alt="alt text" width="240" height="122.5" style="display: block; margin-top: 18.75px; margin-bottom: 18.75px;" />
<td align="left" style="padding-left: 30px;">
<p>
	DARTS-: Robustly Stepping out of Performance Collapse Without Indicators<br />
	Xiangxiang Chu, Xiaoxing Wang, Bo Zhang, <b>Shun Lu</b>, Xiaolin Wei, Junchi Yan<br />
	[ICLR 2021]<a href="https://arxiv.org/abs/2009.01027">[Paper]</a><a href="https://github.com/Meituan-AutoML/DARTS-">[Code]</a>
</p>
</td></tr></table>


<table class="imgtable"><tr><td>
<img src="assets/images/thesis/STC-NAS.png" alt="alt text" width="240" height="126.5" style="display: block; margin-top: 16.75px; margin-bottom: 16.75px;" />
<td align="left" style="padding-left: 30px;">
<p>
	STC-NAS: Fast neural architecture search with source-target consistency<br />
	Zihao Sun, Yu Hu*, Longxing Yang, <b>Shun Lu</b>, Jilin Mei, Yinhe Han, Xiaowei Li<br />
	[Neurocomputing]<a href="https://www.sciencedirect.com/science/article/pii/S0925231221017598">[Paper]</a>
</p>
</td></tr></table>

<table class="imgtable"><tr><td>
<img src="assets/images/thesis/DCDI.jpeg" alt="alt text" width="207" height="160" style="display: block; margin-left: 16.5px; margin-right: 16.5px;" />
<td align="left" style="padding-left: 30px;">
<p>
	Dynamic coherent diffractive imaging with a physics-driven untrained learning method<br />
	Dongyu Yang, Junhao Zhang, Ye Tao, Wenjin Lv, Xinkai Sun, <b>Shun Lu</b>, Hao Chen, Wenhui Xu, Yishi Shi<br />
	[Optics Express]<a href="https://opg.optica.org/oe/fulltext.cfm?uri=oe-29-20-31426&id=458821">[Paper]</a>
</p>
</td></tr></table>


<table class="imgtable"><tr><td>
<img src="assets/images/thesis/MixPath.png" alt="alt text" width="240" height="160" /> &nbsp;</td>
<td align="left" style="padding-left: 30px;">
<p>
	MixPath: A Unified Approach for One-shot Neural Architecture Search<br />
	Xiangxiang Chu, Xudong Li, <b>Shun Lu</b>, Bo Zhang, Jixiang Li<br />
	[arXiv 2020]<a href="https://arxiv.org/abs/2001.05887">[Paper]</a><a href="https://github.com/xiaomi-automl/MixPath">[Code]</a>
</p>
</td></tr></table>

<h2>Competitions</h2> 
<ul>
	<li>
		CVPR 2021 NAS Track 1: Supernet Track, Rank 2nd among all teams from the world.
		<br />
		<b>Shun Lu</b>, Longxing Yang, Jilin Mei
		<br />
	</li>
	<li>
		CVPR 2021 NAS Track 2: Performance Prediction Track, Rank 2nd among all teams from the world.
		<br />
		<b>Shun Lu</b>, Jixiang Li, Jianchao Tan
		<br />
	</li>
</ul>
  
  
<h2> Academic Services</h2>
<ul>
	<b>Conference Reviewer</b>
<li><p>IEEE / CVF Computer Vision and Pattern Recognition Conference (CVPR) 2022</p></li>
<li><p>European Conference on Computer Vision (ECCV) 2022</p></li>
<li><p>International Conference on Computer Vision (ICCV) 2023</p></li>
<li><p>International Conference on Machine Learning (ICML) 2022, 2023</p></li>
<li><p>Neural Information Processing Systems (NeurIPS) 2022, 2023</p></li>
</ul>
  
  
<h2> Honors and Awards</h2> 
<ul> 
<li><p>2023, 中国科学院大学三好学生标兵</p> </li>

</ul>


<table width="100%"> 
	<tr> 
		<td align="center">&copy; Shun Lu | Last update: June 2023</td>
	</tr> 
</table>

</div>


</body>

</html>

